{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37puETfgRzzg"
   },
   "source": [
    "## MMTHE01 - Masters Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Thesis - Create a working model - with SMOTE\n",
    "* Applying SMOTE to the data\n",
    "* When applying SMOTE, it is best not to use one-hot-encoding for categorical data. Therefore the data is imported before encoding and and all categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "#### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Semester 4\\Masters Thesis Report\\6. Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "#### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train_dataset_final_unencoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>C3</th>\n",
       "      <th>C9</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>...</th>\n",
       "      <th>V304</th>\n",
       "      <th>V305</th>\n",
       "      <th>V309</th>\n",
       "      <th>V310</th>\n",
       "      <th>V311</th>\n",
       "      <th>V312</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V318</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  TransactionDT  TransactionAmt ProductCD  card1   C3   C9  C12  \\\n",
       "0        0          86400            68.5         W  13926  0.0  1.0  0.0   \n",
       "1        0          86401            29.0         W   2755  0.0  0.0  0.0   \n",
       "2        0          86469            59.0         W   4663  0.0  1.0  0.0   \n",
       "3        0          86499            50.0         W  18132  0.0  1.0  0.0   \n",
       "4        0          86506            50.0         H   4497  0.0  0.0  0.0   \n",
       "\n",
       "    C13  C14  ...  V304  V305  V309   V310  V311   V312  V314  V315   V318  \\\n",
       "0   1.0  1.0  ...   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "1   1.0  1.0  ...   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "2   1.0  1.0  ...   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "3  25.0  1.0  ...   0.0   1.0   0.0  354.0   0.0  135.0   0.0   0.0  790.0   \n",
       "4   1.0  1.0  ...   1.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "\n",
       "  V321  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 189)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 189 entries, isFraud to V321\n",
      "dtypes: float64(175), int64(4), object(10)\n",
      "memory usage: 851.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Encode data using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of categorical features which require encoding\n",
    "categorical_cols = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'M3', 'M4', 'M5', 'M6', 'M9', 'DeviceInfo','ProductCD', 'card4', 'card6', 'M4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_keep_nan(series):\n",
    "    \"\"\"\n",
    "    Label encodes a pandas Series while leaving NaNs untouched.\n",
    "    Returns the encoded series and the fitted encoder.\n",
    "    \"\"\"\n",
    "    # Keep mask of missing values\n",
    "    mask = series.isna()\n",
    "\n",
    "    # Apply LabelEncoder to non-NaN values only\n",
    "    le = LabelEncoder()\n",
    "    encoded = le.fit_transform(series[~mask])\n",
    "\n",
    "    # Create a full-length array with NaNs\n",
    "    full_encoded = pd.Series(np.nan, index=series.index)\n",
    "    full_encoded[~mask] = encoded\n",
    "\n",
    "    return full_encoded, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['P_emaildomain'], email_encoder = label_encode_keep_nan(dataset['P_emaildomain'])\n",
    "dataset['DeviceInfo'], device_infoencoder = label_encode_keep_nan(dataset['DeviceInfo'])\n",
    "dataset['ProductCD'], email_encoder = label_encode_keep_nan(dataset['ProductCD'])\n",
    "dataset['card4'], device_infoencoder = label_encode_keep_nan(dataset['card4'])\n",
    "dataset['card6'], email_encoder = label_encode_keep_nan(dataset['card6'])\n",
    "dataset['M4'], device_infoencoder = label_encode_keep_nan(dataset['M4'])\n",
    "dataset[\"M3\"] = dataset[\"M3\"].map({\"T\": 1, \"F\": 0})\n",
    "dataset[\"M5\"] = dataset[\"M5\"].map({\"T\": 1, \"F\": 0})\n",
    "dataset[\"M6\"] = dataset[\"M6\"].map({\"T\": 1, \"F\": 0})\n",
    "dataset[\"M9\"] = dataset[\"M9\"].map({\"T\": 1, \"F\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Split the data into Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Separate the features and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = dataset.drop('TransactionID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = dataset_final.iloc[:, 1:].values\n",
    "#y = dataset_final.iloc[:,0].values\n",
    "\n",
    "X = dataset_final.iloc[:, 1:]\n",
    "y = dataset_final.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_im, X_test, y_train_im, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>C3</th>\n",
       "      <th>C9</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>...</th>\n",
       "      <th>V304</th>\n",
       "      <th>V305</th>\n",
       "      <th>V309</th>\n",
       "      <th>V310</th>\n",
       "      <th>V311</th>\n",
       "      <th>V312</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V318</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  TransactionDT  TransactionAmt  ProductCD  card1   C3   C9  C12  \\\n",
       "0        0          86400            68.5        4.0  13926  0.0  1.0  0.0   \n",
       "1        0          86401            29.0        4.0   2755  0.0  0.0  0.0   \n",
       "2        0          86469            59.0        4.0   4663  0.0  1.0  0.0   \n",
       "3        0          86499            50.0        4.0  18132  0.0  1.0  0.0   \n",
       "4        0          86506            50.0        1.0   4497  0.0  0.0  0.0   \n",
       "\n",
       "    C13  C14  ...  V304  V305  V309   V310  V311   V312  V314  V315   V318  \\\n",
       "0   1.0  1.0  ...   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "1   1.0  1.0  ...   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "2   1.0  1.0  ...   0.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "3  25.0  1.0  ...   0.0   1.0   0.0  354.0   0.0  135.0   0.0   0.0  790.0   \n",
       "4   1.0  1.0  ...   1.0   1.0   0.0    0.0   0.0    0.0   0.0   0.0    0.0   \n",
       "\n",
       "   V321  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Applying SMOTE_NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical feature indices\n",
    "categorical_features = [dataset_final.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "smote_nc = SMOTENC(categorical_features=categorical_features, random_state=1)\n",
    "\n",
    "X_chunks_resampled = []\n",
    "y_chunks_resampled = []\n",
    "\n",
    "chunk_size = 50000  # adjust as needed\n",
    "\n",
    "\n",
    "\n",
    "for start in range(0, len(dataset_final), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = dataset_final.iloc[start:end]\n",
    "\n",
    "    X_chunk = chunk.drop(columns=['isFraud'])\n",
    "    y_chunk = chunk['isFraud']\n",
    "\n",
    "    # Fit-resample\n",
    "    X_res, y_res = smote_nc.fit_resample(X_chunk, y_chunk)\n",
    "\n",
    "    # Get correct expanded column names from SMOTENC\n",
    "    ohe_columns = smote_nc.ohe_.get_feature_names_out(\n",
    "        X_chunk.columns[smote_nc.categorical_features]\n",
    "    )\n",
    "    numeric_columns = X_chunk.drop(\n",
    "        columns=X_chunk.columns[smote_nc.categorical_features]\n",
    "    ).columns\n",
    "    expanded_columns = list(numeric_columns) + list(ohe_columns)\n",
    "\n",
    "    # Convert resampled data to DataFrame with proper column names\n",
    "    X_res_df = pd.DataFrame(X_res, columns=expanded_columns)\n",
    "\n",
    "    X_chunks_resampled.append(X_res_df)\n",
    "    y_chunks_resampled.append(pd.Series(y_res, name='isFraud'))\n",
    "\n",
    "\n",
    "\n",
    "# Combine all resampled chunks into one DataFrame\n",
    "X_final = pd.concat(X_chunks_resampled, ignore_index=True)\n",
    "y_final = pd.concat(y_chunks_resampled, ignore_index=True)\n",
    "\n",
    "# Get one full dataframe\n",
    "resampled_df = pd.concat([X_final, y_final], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical feature indices\n",
    "categorical_features = [dataset_final.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "# Instantiate SMOTE-NC\n",
    "smote_nc = SMOTENC(categorical_features=categorical_features,  k_neighbors=3, sampling_strategy=0.5, random_state=1)\n",
    "\n",
    "\n",
    "# ====== Chunking parameters ======\n",
    "chunk_size = 50000  # adjust to fit your memory budget\n",
    "X_chunks = []\n",
    "y_chunks = []\n",
    "\n",
    "# ====== Oversample each chunk ======\n",
    "# Only chunk the majority class and oversample minority in each\n",
    "minority_label = y_train_im.value_counts().idxmin()\n",
    "\n",
    "dataset_final = X_train_im.copy()\n",
    "dataset_final['isFraud'] = y_train_im\n",
    "\n",
    "# Separate classes\n",
    "df_minority = dataset_final[dataset_final['isFraud'] == minority_label]\n",
    "df_majority = dataset_final[dataset_final['isFraud'] != minority_label]\n",
    "\n",
    "\n",
    "df_minority.shape\n",
    "\n",
    "df_majority.shape\n",
    "\n",
    "df_majority.head()\n",
    "\n",
    "\n",
    "\n",
    "# Process the majority class in chunks\n",
    "for start in range(0, len(df_majority), chunk_size):\n",
    "    maj_chunk = df_majority.iloc[start:start+chunk_size]\n",
    "    combined_chunk = pd.concat([maj_chunk, df_minority], axis=0)\n",
    "\n",
    "    X_chunk = combined_chunk.drop('isFraud', axis=1).values\n",
    "    y_chunk = combined_chunk['isFraud'].values\n",
    "\n",
    "    # Oversample this chunk\n",
    "    X_res, y_res = smote_nc.fit_resample(X_chunk, y_chunk)\n",
    "\n",
    "    X_chunks.append(X_res)\n",
    "    y_chunks.append(y_res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====== Combine all chunks ======\n",
    "X_train = pd.concat([pd.DataFrame(x) for x in X_chunks], ignore_index=True)\n",
    "y_train = pd.concat([pd.Series(y) for y in y_chunks], ignore_index=True)\n",
    "\n",
    "print(\"Final resampled shape:\", X_train.shape, y_train_resampled.shape)\n",
    "print(\"Class counts:\", y_train.value_counts())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Unsupervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.035,  # Approximate fraud ratio in dataset\n",
    "    max_samples='auto',\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Isolation Forest Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict: -1 for outliers (fraud), 1 for inliers (non-fraud)\n",
    "y_pred = iso_forest.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 1 for fraud, 0 for non-fraud to match label\n",
    "y_pred_binary = np.where(y_pred == -1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use anomaly scores for ROC AUC\n",
    "y_pred_proba = iso_forest.decision_function(X_test_scaled)*-1  # Higher score = more anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba,pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"Isolation Forest - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('Isolation Forest - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('Isolation Forest - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the Isolation Forest model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred_binary, pos_label=1)\n",
    "print(f\"Isolation Forest Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the Isolation Forest to determine its sensitivity\n",
    "\n",
    "precision = precision_score(y_test, y_pred_binary, pos_label=1)\n",
    "print(f\"Isolation Forest Precision Score: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Training is done on only on non-fraudulent samples\n",
    "X_train_ae = X_train_scaled[y_train == 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the autoencoder\n",
    "input_dim = X_train_ae.shape[1]\n",
    "encoding_dim = 32  # compressed representation size\n",
    "\n",
    "input_layer = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_layer)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded = layers.Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = models.Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    X_train_ae, X_train_ae,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Autoencoder Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction errors on test data\n",
    "X_test_pred = autoencoder.predict(X_test_scaled)\n",
    "mse = np.mean(np.power(X_test_scaled - X_test_pred, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate anomaly detection performance\n",
    "# A simple threshold for anomaly score\n",
    "threshold = np.percentile(mse[y_test == 0], 95)  # 95th percentile of reconstruction error on non-fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict fraud if reconstruction error > threshold\n",
    "y_pred = (mse > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba,pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"Autoencoder - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('Autoencoder - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('Autoencoder - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the Autoencoder model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Autoencoder Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the Autoencoder\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Autoencoder Precision Score: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Supervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Random Forest Model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Random Forest Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y given X_test\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1],pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"Random Forest - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('Random Forest - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('Random Forest - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the Random Forest model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Random Forest Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the Random Forest\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Random Forest Precision Score: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an XGBoost Model\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=5,  # Adjust based on imbalance\n",
    "    eval_metric='auc',\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the XGBoost model\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"XGBoost Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y given X_test\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1],pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"XGBoost - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('XGBoost - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('XGBoost - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the XGBoost model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"XGBoost Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the XGBoost Model\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"XGBoost Precision Score: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3 Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an ANN model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer instead of input_dim in Dense\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_AUC', patience=3, restore_best_weights=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ANN model with timing\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"ANN Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y given X_test_scaled\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba,pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"ANN - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ANN - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('ANN - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the ANN model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"ANN Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the ANN model\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"ANN Precision Score {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.4 K Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the KNN model\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"KNN Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y given X_test_scaled\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "y_pred_proba = knn.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1],pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"KNN - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('KNN - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('KNN - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the baseline model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"KNN Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the KNN model\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"KNN Precision Score (Sensitivity): {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5 Support Vector Machine (SVM) - Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline with scaling + LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', LinearSVC(class_weight='balanced', max_iter=10000, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "pipeline.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"SVM Base Model Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y given X_test_scaled\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "y_pred_proba = pipeline.decision_function(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba,pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"SVM - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('SVM - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('SVM - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the baseline model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"SVM Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the SVM model\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"SVM Precision Score {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.6 Gradient Boosting Machine (GBM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GBM model\n",
    "gbm = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5, \n",
    "    subsample=0.8,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"GBM Training Time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y given X_test\n",
    "y_pred = gbm.predict(X_test)\n",
    "y_pred_proba = gbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1],pos_label=1)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"GBM - with SMOTE AUC (in %):\", auc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curve\n",
    "# plot roc curves\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, thresholds = roc_curve(y_test, random_probs, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle='--', color='orange')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('GBM - with SMOTE ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.savefig('GBM - with SMOTE ROC curve',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate recall_score of the baseline model to determine its sensitivity\n",
    "\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"GBM Recall Score (Sensitivity): {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate precision_score of the SVM model\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"GBM Precision Score {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Cross Validation Checks for the Supervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7.1 Cross Validation for the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "aucs = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(\"AUC Random Forest: {:.3f} %\".format(aucs.mean()*100))\n",
    "print(\"AUC Standard Deviation Random Forest: {:.5f}\".format(aucs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10, scoring=\"recall\")\n",
    "print(\"Recall Random Forest: {:.4f}\".format(recalls.mean()))\n",
    "print(\"Recall Standard Deviation Random Forest: {:.5f}\".format(recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(estimator = rf, X = X_train, y = y_train, cv = 10, scoring=\"precision\")\n",
    "print(\"Precision Random Forest: {:.4f}\".format(precisions.mean()))\n",
    "print(\"Precision Standard Deviation Random Forest: {:.5f}\".format(precisions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7.2 Cross Validation for the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = cross_val_score(estimator = xgb, X = X_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(\"AUC XGBoost: {:.3f} %\".format(aucs.mean()*100))\n",
    "print(\"AUC Standard Deviation XGBoost: {:.5f}\".format(aucs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = cross_val_score(estimator = xgb, X = X_train, y = y_train, cv = 10, scoring=\"recall\")\n",
    "print(\"Recall XGBoost: {:.4f}\".format(recalls.mean()))\n",
    "print(\"Recall Standard Deviation XGBoost: {:.5f}\".format(recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(estimator = xgb, X = X_train, y = y_train, cv = 10, scoring=\"precision\")\n",
    "print(\"Precision XGBoost: {:.4f}\".format(precisions.mean()))\n",
    "print(\"Precision Standard Deviation XGBoost: {:.5f}\".format(precisions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7.3 Cross Validation for the KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = cross_val_score(estimator = knn, X = X_train_scaled, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(\"AUC KNN: {:.3f} %\".format(aucs.mean()*100))\n",
    "print(\"AUC Standard Deviation KNN: {:.5f}\".format(aucs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = cross_val_score(estimator = knn, X = X_train_scaled, y = y_train, cv = 10, scoring=\"recall\")\n",
    "print(\"Recall KNN: {:.4f}\".format(recalls.mean()))\n",
    "print(\"Recall Standard Deviation KNN: {:.5f}\".format(recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(estimator = knn, X = X_train, y = y_train, cv = 10, scoring=\"precision\")\n",
    "print(\"Precision KNN: {:.4f}\".format(precisions.mean()))\n",
    "print(\"Precision Standard Deviation KNN: {:.5f}\".format(precisions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.4 Cross Validation for the SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = cross_val_score(estimator = pipeline, X = X_train_scaled, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(\"AUC SVM: {:.3f} %\".format(aucs.mean()*100))\n",
    "print(\"AUC Standard Deviation SVM: {:.5f}\".format(aucs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = cross_val_score(estimator = pipeline, X = X_train_scaled, y = y_train, cv = 10, scoring=\"recall\")\n",
    "print(\"Recall SVM: {:.4f}\".format(recalls.mean()))\n",
    "print(\"Recall Standard Deviation SVM: {:.5f}\".format(recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(estimator = pipeline, X = X_train, y = y_train, cv = 10, scoring=\"precision\")\n",
    "print(\"Precision SVM: {:.4f}\".format(precisions.mean()))\n",
    "print(\"Precision Standard Deviation SVM: {:.5f}\".format(precisions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7.5 Cross Validation for the GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = cross_val_score(estimator = gbm, X = X_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(\"AUC GBM: {:.3f} %\".format(aucs.mean()*100))\n",
    "print(\"AUC Standard Deviation GBM: {:.5f}\".format(aucs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "recalls = cross_val_score(estimator = gbm, X = X_train, y = y_train, cv = 10, scoring=\"recall\")\n",
    "print(\"Recall GBM: {:.4f}\".format(recalls.mean()))\n",
    "print(\"Recall Standard Deviation GBM: {:.5f}\".format(recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(estimator = gbm, X = X_train, y = y_train, cv = 10, scoring=\"precision\")\n",
    "print(\"Precision GBM: {:.4f}\".format(precisions.mean()))\n",
    "print(\"Precision Standard Deviation GBM: {:.5f}\".format(precisions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOihYlX/ooG5h+qw0sLIjn8",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
