{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66782e3a",
   "metadata": {},
   "source": [
    "## MMTHE01 - Masters Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bec9f",
   "metadata": {},
   "source": [
    "### E3. Thesis - Apply and Evaluate different XAI methods - Case Study with the ANN Model\n",
    "\n",
    "* Applying XAI on a Deep Learning AI model (ANN Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166f4f1-fbbb-4985-af8b-8f4ddc244cc3",
   "metadata": {},
   "source": [
    "#### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff01cd-dd98-4ab5-80d5-20db0794bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import general libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fa0cb-3a99-4418-b435-c40bc081f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define your relative path\n",
    "relative_path = r\"6. Analysis\"  # adjust this relative to cwd\n",
    "\n",
    "# Build the full path\n",
    "full_path = os.path.join(cwd, relative_path)\n",
    "\n",
    "# Check if it exists before changing\n",
    "if os.path.exists(full_path):\n",
    "    os.chdir(full_path)\n",
    "    print(\"Changed directory to:\", full_path)\n",
    "else:\n",
    "    print(\"Folder does not exist:\", full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5e01d-ed0c-4527-96b6-f6c5edb9ef59",
   "metadata": {},
   "source": [
    "#### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75b239-433a-4ad1-9210-58038649e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train_dataset_final_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0fbb10-0af9-4314-aff5-046be20b0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac94f5-1551-4af7-ae4b-e1741b7e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87977dd-aa84-4b58-9650-0d665fcda431",
   "metadata": {},
   "source": [
    "### 5.1 Split the data into Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56198e-d54a-48b7-af89-327b97e5fa00",
   "metadata": {},
   "source": [
    "#### 5.1.1 Separate the features and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203eb3e-4fd5-46ff-ae8a-9f19f28fc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = dataset.drop('TransactionID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c272214-395c-4d26-9bbe-3fa71a559a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = dataset.iloc[:, 1:].values\n",
    "#y = dataset.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c73d18-12ea-4953-bacc-f1514b8b0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_final.iloc[:, 1:]\n",
    "y = dataset_final.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa73da-cd40-4621-af54-e993fe1c0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_im, X_test, y_train_im, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8276cc-75da-4969-938c-68ea0251c511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f9cc0d-d775-48af-b470-6273d9e541f9",
   "metadata": {},
   "source": [
    "### 5.2 Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b2ea9-8047-45ee-8089-1419c82b3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SMOTE only to the training data\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train, y_train = smote.fit_resample(X_train_im, y_train_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ddffb-5bf9-4e01-b39a-8c25bf4c622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59bd8d5-0918-4671-a1ae-690ae71e8824",
   "metadata": {},
   "source": [
    "### 5.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbab600-ae2a-4923-9624-edc62166f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_tn_scaled = sc.fit_transform(X_train)\n",
    "X_tt_scaled = sc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "# Convert to dataframe\n",
    "X_train_scaled = pd.DataFrame(X_tn_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_tt_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891cc37a-8ee0-40db-9626-25c0192a2f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd656b46-49f6-454e-a324-d5e75f67abc1",
   "metadata": {},
   "source": [
    "### 5.4 Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb69d018-0547-479c-9dfb-cb171892d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a01499-9fd5-4bcc-89c3-e8599efd9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an ANN model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer instead of input_dim in Dense\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_AUC', patience=3, restore_best_weights=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799eb3ab-c96c-485c-8383-35a32e3f7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ANN model with timing\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b12b83-6b8c-49c3-bc79-63049e441d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b405e695-e767-4cd1-a988-864a58ff6e09",
   "metadata": {},
   "source": [
    "### 5.5 Applying XAI methods to the ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb2d8b-2e15-4db4-a010-b4559825a95a",
   "metadata": {},
   "source": [
    "#### 5.5.6 Applying Permutation Importance to the ANN Model\n",
    "* E3D. Thesis - Test different XAI methods with the ANN Model (Permutation Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa908627-77ec-4e88-87aa-f41a6dd32467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbfe0e-520c-4630-8672-79cae3fabfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create an sklearn wrapper to prevent \n",
    "AttributeError: Sequential has none of the following attributes: decision_function, predict_proba.\n",
    "'''\n",
    "class SklearnANNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        # set classes for binary classification\n",
    "        self.classes_ = np.array([0, 1])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # dummy fit\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probs = self.model.predict(X)\n",
    "        return np.hstack([1 - probs, probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01305ca-5e68-4564-ac18-70907a6d9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap your trained model\n",
    "sklearn_model = SklearnANNWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d26fb-6f49-43ca-b6a9-0e27bc5e3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = old_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e3e2d-754d-4dc6-889a-377f42b525ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c05492-46a0-4800-b8e1-a5ce372205f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute permutation importance\n",
    "# Use sklearn_model instead of model so as to prevent attribute errors\n",
    "with suppress_stdout():\n",
    "    result = permutation_importance(\n",
    "        sklearn_model,\n",
    "        X_test_scaled,\n",
    "        y_test,\n",
    "        n_repeats=10,\n",
    "        random_state=42,\n",
    "        scoring='roc_auc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69dc4f-1809-40e9-b7a7-66aa364f4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "explanation_time = end_time - start_time\n",
    "print(f\"Permutation Important on ANN (Explanation Time): {explanation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920bd25-989c-4bd5-857f-716779bb0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in DataFrame\n",
    "pi_df = pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b947f-b030-4793-ad87-cabec8da1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pi_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591007d-619f-4e08-9ff9-89e85daf751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 features\n",
    "top_n = 10\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(pi_df['feature'].head(top_n)[::-1], pi_df['importance_mean'].head(top_n)[::-1])\n",
    "plt.xlabel(\"Permutation Importance (Mean decrease in ROC-AUC)\")\n",
    "plt.title(\"Top Features by Permutation Importance - ANN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed923b-9b5c-4aee-b266-3f079a6d26bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b2d0b-37c1-4f9e-ba68-291284f4961f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92698411-c383-4020-83d4-e984d3078517",
   "metadata": {},
   "source": [
    "#### 5.5.2 Applying Counterfactual to the ANN Model\n",
    "* E3D. Thesis - Test different XAI methods with the ANN Model (Counterfactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fad931-cfb1-4ba4-8800-5c4863a5f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902ce86-641a-4980-b3c8-8293193ac671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show floats with 2 decimal places and avoid scientific notation\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26253c77-399c-4ec0-a38e-4cb2514cc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume: X_train, X_test, model\n",
    "query_instance = X_test_scaled.iloc[0].copy()\n",
    "query_instance_values = query_instance.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b1d22-9da5-4393-9022-c672bd70ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, x):\n",
    "    \"\"\"\n",
    "    Predict class for a single instance.\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(x.reshape(1, -1))[0,1]  # probability of class 1\n",
    "    else:\n",
    "        return model.predict(x.reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9c3da-f3ea-49a7-874c-1fadb934987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2):\n",
    "    \"\"\"Euclidean distance between two instances\"\"\"\n",
    "    return np.linalg.norm(x1 - x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ff7fb-0e6a-43db-9d90-42320c7df0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfactual(model, x0, total_cfs=3, max_trials=10000, step_size=0.1):\n",
    "    \"\"\"\n",
    "    Generates counterfactuals using random perturbations.\n",
    "    \"\"\"\n",
    "    cf_list = []\n",
    "    trials = 0\n",
    "    \n",
    "    while len(cf_list) < total_cfs and trials < max_trials:\n",
    "        # Perturb features randomly\n",
    "        x_cf = x0 + np.random.normal(0, step_size, size=x0.shape)\n",
    "        \n",
    "        # Check if prediction flips\n",
    "        pred_orig = predict_label(model, x0)\n",
    "        pred_cf = predict_label(model, x_cf)\n",
    "        \n",
    "        # For binary classification, flip the label\n",
    "        if (pred_orig < 0.5 and pred_cf >= 0.5) or (pred_orig >= 0.5 and pred_cf < 0.5):\n",
    "            cf_list.append(x_cf)\n",
    "        \n",
    "        trials += 1\n",
    "    \n",
    "    return np.array(cf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28644c6-46ab-490b-8680-c469dba1195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf459a7-4284-4f08-b2a3-da49a18cf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals = generate_counterfactual(model=model, x0=query_instance_values, total_cfs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fff76a-530d-4baa-8746-96b8e4760d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "explanation_time = end_time - start_time\n",
    "print(f\"Counterfactual on ANN (Explanation Time): {explanation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a5e2e-b160-40e8-9b45-1190dfc02240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = pd.DataFrame(counterfactuals, columns=X_test_scaled.columns)\n",
    "df_compare = pd.concat([query_instance.to_frame().T, df_cf], keys=['Original', 'Counterfactual'])\n",
    "df_transposed = df_compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651168c7-4fa9-4325-afa6-1de5edf40a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d9da6-430e-46cc-a713-2e9264658dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77c6f4-f330-4e55-896d-ee376a44849e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b90c489-041f-4b33-9a99-ebb9871a28cd",
   "metadata": {},
   "source": [
    "#### 5.5.3 Applying Adversarial Explanations to the ANN Model\n",
    "* E3D. Thesis - Test different XAI methods with the ANN Model (Adversarial Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52614b05-e111-4d51-b709-c9013bd02f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67243e-845e-4e66-a91e-97220569a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define adversarial explanation function \n",
    "def adversarial_explanation(model,\n",
    "    x_orig,                     # 1D numpy array (already preprocessed to model input space)\n",
    "    target_label=None,          # desired target label (0 or 1). If None -> flip original label.\n",
    "    feature_bounds=None,        # list of (min, max) for each feature (in same scaled space as x_orig)\n",
    "    maxiter=200,                # DE iterations\n",
    "    popsize=15,                 # DE population size multiplier\n",
    "    penalty_coef=50.0,          # strength of constraint penalty\n",
    "    norm='l2',                  # 'l2' or 'linf'\n",
    "    random_state=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Find a minimal perturbation delta such that model.predict_proba(x_orig + delta) yields target_label.\n",
    "    Uses differential_evolution (global, gradient-free).\n",
    "    Returns: dict { 'delta', 'x_adv', 'orig_prob', 'adv_prob', 'success', 'distance' }\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    x_orig = np.asarray(x_orig).astype(float).ravel()\n",
    "    n = x_orig.size\n",
    "\n",
    "    # current predicted label and probability\n",
    "    prob_orig = model.predict_proba(x_orig.reshape(1, -1))[0,1]\n",
    "    label_orig = int(prob_orig >= 0.5)\n",
    "    if target_label is None:\n",
    "        target = 1 - label_orig\n",
    "    else:\n",
    "        target = int(target_label)\n",
    "\n",
    "    # bounds for delta: by default allow changes within (min_feature - val, max_feature - val)\n",
    "    if feature_bounds is None:\n",
    "        # set bounds from training feature ranges (we'll use training min/max scaled)\n",
    "        # Compute safe bounds around x_orig: +/- 3 STD (in scaled space that's reasonable)\n",
    "        # but to be general, allow range [-clip, +clip] where clip = max(abs(min,max)) * 1.1\n",
    "        # Here we set per-feature bounds to ensure we stay inside plausible values.\n",
    "        fb = []\n",
    "        X_all = np.vstack([X_train_scaled.values, X_test_scaled.values])\n",
    "        min_col = X_all[:, :].min(axis=0)\n",
    "        max_col = X_all[:, :].max(axis=0)\n",
    "        for i in range(n):\n",
    "            # bounds for delta so that x_adv remains in [min_col[i], max_col[i]]\n",
    "            lo = min_col[i] - x_orig[i]\n",
    "            hi = max_col[i] - x_orig[i]\n",
    "            fb.append((lo, hi))\n",
    "    else:\n",
    "        # feature_bounds given as list of (min,max) for each feature in input space\n",
    "        fb = []\n",
    "        for i, (mn, mx) in enumerate(feature_bounds):\n",
    "            fb.append((mn - x_orig[i], mx - x_orig[i]))\n",
    "\n",
    "    # objective: minimize norm(delta) + penalty * max(0, threshold - prob_target)\n",
    "    def objective(delta_flat):\n",
    "        delta = np.array(delta_flat)\n",
    "        x_candidate = x_orig + delta\n",
    "        # clip to bounds (avoid invalid values)\n",
    "        # compute predicted probability of target class\n",
    "        proba = model.predict_proba(x_candidate.reshape(1, -1))[0, 1]\n",
    "        # fitness for target: we want proba_target >= 0.5 if target==1; else <=0.5\n",
    "        if target == 1:\n",
    "            violation = max(0.0, 0.5 - proba)\n",
    "        else:\n",
    "            violation = max(0.0, proba - 0.5)\n",
    "        # distance measure\n",
    "        if norm == 'l2':\n",
    "            dist = np.linalg.norm(delta)\n",
    "        elif norm == 'linf':\n",
    "            dist = np.max(np.abs(delta))\n",
    "        else:\n",
    "            dist = np.linalg.norm(delta)\n",
    "        # objective: distance + penalty * violation\n",
    "        return dist + penalty_coef * violation\n",
    "\n",
    "    # differential evolution\n",
    "    result = differential_evolution(\n",
    "        objective,\n",
    "        fb,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popsize,\n",
    "        tol=1e-5,\n",
    "        polish=True,\n",
    "        updating='deferred',\n",
    "        seed=random_state,\n",
    "        mutation=(0.5, 1.0),\n",
    "        recombination=0.7,\n",
    "    )\n",
    "\n",
    "    delta_opt = result.x\n",
    "    x_adv = x_orig + delta_opt\n",
    "    prob_adv = model.predict_proba(x_adv.reshape(1, -1))[0,1]\n",
    "    success = (prob_adv >= 0.5 and target == 1) or (prob_adv < 0.5 and target == 0)\n",
    "    distance = np.linalg.norm(delta_opt) if norm == 'l2' else np.max(np.abs(delta_opt))\n",
    "\n",
    "    return {\n",
    "        'delta': delta_opt,\n",
    "        'x_adv': x_adv,\n",
    "        'orig_prob': prob_orig,\n",
    "        'adv_prob': prob_adv,\n",
    "        'success': success,\n",
    "        'distance': distance,\n",
    "        'result_obj': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7265775-e4d0-4cc1-a2e8-98bec78e1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded12e2-b7e0-463f-9ee2-5acddb98d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run adversarial explanation for one test instance\n",
    "idx = 0\n",
    "x0 = X_test_scaled.iloc[idx].values  # already scaled to model input\n",
    "ae = adversarial_explanation(model, x0, target_label=None, maxiter=100, popsize=10, penalty_coef=200.0, norm='l2', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73baa5-1825-4fae-9598-e906ff475f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "explanation_time = end_time - start_time\n",
    "print(f\"Adversarial Expanations on ANN (Explanation Time): {explanation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f522e8-2aca-40f2-9ea1-240e8e17ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original prob (class=1):\", ae['orig_prob'])\n",
    "print(\"Adversarial prob (class=1):\", ae['adv_prob'])\n",
    "print(\"Success flipped?:\", ae['success'])\n",
    "print(\"L2 distance of delta:\", ae['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0f839-ec1f-47e4-b9b4-da066387b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top changed features\n",
    "delta = ae['delta']\n",
    "df_changes = pd.DataFrame({\n",
    "    'feature': X_test_scaled.columns,\n",
    "    'orig': x0,\n",
    "    'adv': ae['x_adv'],\n",
    "    'delta': delta,\n",
    "    'abs_delta': np.abs(delta)\n",
    "}).sort_values('abs_delta', ascending=False)\n",
    "\n",
    "print(\"\\nTop feature changes (by absolute perturbation):\")\n",
    "print(df_changes.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233cecd-1fcd-4b7e-9e7c-1aecb1c959fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 10 features by absolute change\n",
    "top_changes = df_changes.head(10).sort_values('abs_delta', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(top_changes['feature'], top_changes['delta'], color='skyblue')\n",
    "plt.xlabel('Change (delta)')\n",
    "plt.title('Top 10 Features Changed by Adversarial Example')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00c023-c01e-4718-82dc-7686157ad82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38c796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
