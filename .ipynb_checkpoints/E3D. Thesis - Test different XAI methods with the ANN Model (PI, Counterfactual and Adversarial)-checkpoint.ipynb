{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66782e3a",
   "metadata": {},
   "source": [
    "## MMTHE01 - Masters Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bec9f",
   "metadata": {},
   "source": [
    "### E3. Thesis - Apply and Evaluate different XAI methods - Case Study with the ANN Model\n",
    "\n",
    "* Applying XAI on a Deep Learning AI model (ANN Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166f4f1-fbbb-4985-af8b-8f4ddc244cc3",
   "metadata": {},
   "source": [
    "#### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcff01cd-dd98-4ab5-80d5-20db0794bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import general libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309fa0cb-3a99-4418-b435-c40bc081f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Semester 4\\Masters Thesis Report\\6. Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5e01d-ed0c-4527-96b6-f6c5edb9ef59",
   "metadata": {},
   "source": [
    "#### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a75b239-433a-4ad1-9210-58038649e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train_dataset_final_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0fbb10-0af9-4314-aff5-046be20b0a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>C3</th>\n",
       "      <th>C9</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>...</th>\n",
       "      <th>card4_discover</th>\n",
       "      <th>card4_mastercard</th>\n",
       "      <th>card4_visa</th>\n",
       "      <th>card6_charge card</th>\n",
       "      <th>card6_credit</th>\n",
       "      <th>card6_debit</th>\n",
       "      <th>card6_debit or credit</th>\n",
       "      <th>M4_M0</th>\n",
       "      <th>M4_M1</th>\n",
       "      <th>M4_M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2987001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2987002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2987003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2987004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  TransactionDT  TransactionAmt  card1   C3   C9  C12   C13  C14  \\\n",
       "0        0          86400            68.5  13926  0.0  1.0  0.0   1.0  1.0   \n",
       "1        0          86401            29.0   2755  0.0  0.0  0.0   1.0  1.0   \n",
       "2        0          86469            59.0   4663  0.0  1.0  0.0   1.0  1.0   \n",
       "3        0          86499            50.0  18132  0.0  1.0  0.0  25.0  1.0   \n",
       "4        0          86506            50.0   4497  0.0  0.0  0.0   1.0  1.0   \n",
       "\n",
       "   TransactionID  ...  card4_discover  card4_mastercard  card4_visa  \\\n",
       "0        2987000  ...             1.0               0.0         0.0   \n",
       "1        2987001  ...             0.0               1.0         0.0   \n",
       "2        2987002  ...             0.0               0.0         1.0   \n",
       "3        2987003  ...             0.0               1.0         0.0   \n",
       "4        2987004  ...             0.0               1.0         0.0   \n",
       "\n",
       "   card6_charge card  card6_credit  card6_debit  card6_debit or credit  M4_M0  \\\n",
       "0                0.0           1.0          0.0                    0.0    0.0   \n",
       "1                0.0           1.0          0.0                    0.0    1.0   \n",
       "2                0.0           0.0          1.0                    0.0    1.0   \n",
       "3                0.0           0.0          1.0                    0.0    1.0   \n",
       "4                0.0           1.0          0.0                    0.0    1.0   \n",
       "\n",
       "   M4_M1  M4_M2  \n",
       "0    0.0    1.0  \n",
       "1    0.0    0.0  \n",
       "2    0.0    0.0  \n",
       "3    0.0    0.0  \n",
       "4    0.0    0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fac94f5-1551-4af7-ae4b-e1741b7e7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 201)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87977dd-aa84-4b58-9650-0d665fcda431",
   "metadata": {},
   "source": [
    "### 5.1 Split the data into Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56198e-d54a-48b7-af89-327b97e5fa00",
   "metadata": {},
   "source": [
    "#### 5.1.1 Separate the features and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1203eb3e-4fd5-46ff-ae8a-9f19f28fc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = dataset.drop('TransactionID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c272214-395c-4d26-9bbe-3fa71a559a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = dataset.iloc[:, 1:].values\n",
    "#y = dataset.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c73d18-12ea-4953-bacc-f1514b8b0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_final.iloc[:, 1:]\n",
    "y = dataset_final.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1caa73da-cd40-4621-af54-e993fe1c0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8276cc-75da-4969-938c-68ea0251c511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f9cc0d-d775-48af-b470-6273d9e541f9",
   "metadata": {},
   "source": [
    "### 5.2 Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b2ea9-8047-45ee-8089-1419c82b3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SMOTE only to the training data\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train, y_train = smote.fit_resample(X_train_im, y_train_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ddffb-5bf9-4e01-b39a-8c25bf4c622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59bd8d5-0918-4671-a1ae-690ae71e8824",
   "metadata": {},
   "source": [
    "### 5.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbab600-ae2a-4923-9624-edc62166f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_tn_scaled = sc.fit_transform(X_train)\n",
    "X_tt_scaled = sc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "# Convert to dataframe\n",
    "X_train_scaled = pd.DataFrame(X_tn_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_tt_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891cc37a-8ee0-40db-9626-25c0192a2f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd656b46-49f6-454e-a324-d5e75f67abc1",
   "metadata": {},
   "source": [
    "### 5.4 Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb69d018-0547-479c-9dfb-cb171892d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a01499-9fd5-4bcc-89c3-e8599efd9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an ANN model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer instead of input_dim in Dense\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_AUC', patience=3, restore_best_weights=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799eb3ab-c96c-485c-8383-35a32e3f7d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - AUC: 0.7477 - loss: 0.1595 - val_AUC: 0.8621 - val_loss: 0.1040\n",
      "Epoch 2/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - AUC: 0.8437 - loss: 0.1094 - val_AUC: 0.8731 - val_loss: 0.1007\n",
      "Epoch 3/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - AUC: 0.8543 - loss: 0.1051 - val_AUC: 0.8769 - val_loss: 0.0990\n",
      "Epoch 4/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - AUC: 0.8676 - loss: 0.1010 - val_AUC: 0.8814 - val_loss: 0.0970\n",
      "Epoch 5/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8759 - loss: 0.0978 - val_AUC: 0.8856 - val_loss: 0.0952\n",
      "Epoch 6/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8777 - loss: 0.0959 - val_AUC: 0.8859 - val_loss: 0.0950\n",
      "Epoch 7/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8801 - loss: 0.0942 - val_AUC: 0.8898 - val_loss: 0.0928\n",
      "Epoch 8/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8842 - loss: 0.0933 - val_AUC: 0.8920 - val_loss: 0.0920\n",
      "Epoch 9/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8848 - loss: 0.0916 - val_AUC: 0.8927 - val_loss: 0.0914\n",
      "Epoch 10/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8882 - loss: 0.0917 - val_AUC: 0.8958 - val_loss: 0.0910\n",
      "Epoch 11/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8879 - loss: 0.0917 - val_AUC: 0.8960 - val_loss: 0.0898\n",
      "Epoch 12/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8899 - loss: 0.0892 - val_AUC: 0.8961 - val_loss: 0.0896\n",
      "Epoch 13/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - AUC: 0.8930 - loss: 0.0902 - val_AUC: 0.8996 - val_loss: 0.0889\n",
      "Epoch 14/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - AUC: 0.8931 - loss: 0.0879 - val_AUC: 0.8977 - val_loss: 0.0891\n",
      "Epoch 15/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8956 - loss: 0.0871 - val_AUC: 0.8984 - val_loss: 0.0886\n",
      "Epoch 16/20\n",
      "\u001b[1m1477/1477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - AUC: 0.8962 - loss: 0.0876 - val_AUC: 0.8987 - val_loss: 0.0894\n"
     ]
    }
   ],
   "source": [
    "# Train the ANN model with timing\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b12b83-6b8c-49c3-bc79-63049e441d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b405e695-e767-4cd1-a988-864a58ff6e09",
   "metadata": {},
   "source": [
    "### 5.5 Applying XAI methods to the ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb2d8b-2e15-4db4-a010-b4559825a95a",
   "metadata": {},
   "source": [
    "#### 5.5.6 Applying Permutation Importance to the ANN Model\n",
    "* E3D. Thesis - Test different XAI methods with the ANN Model (Permutation Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa908627-77ec-4e88-87aa-f41a6dd32467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e3e2d-754d-4dc6-889a-377f42b525ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c05492-46a0-4800-b8e1-a5ce372205f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute permutation importance\n",
    "result = permutation_importance(\n",
    "    model, X_test_scaled, y_test,\n",
    "    n_repeats=10, random_state=42, scoring='roc_auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69dc4f-1809-40e9-b7a7-66aa364f4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "explanation_time = end_time - start_time\n",
    "print(f\"Permutation Important on ANN (Explanation Time): {explanation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920bd25-989c-4bd5-857f-716779bb0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in DataFrame\n",
    "pi_df = pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b947f-b030-4793-ad87-cabec8da1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pi_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591007d-619f-4e08-9ff9-89e85daf751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 features\n",
    "top_n = 10\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(pi_df['feature'].head(top_n)[::-1], pi_df['importance_mean'].head(top_n)[::-1])\n",
    "plt.xlabel(\"Permutation Importance (Mean decrease in ROC-AUC)\")\n",
    "plt.title(\"Top Features by Permutation Importance - ANN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed923b-9b5c-4aee-b266-3f079a6d26bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b2d0b-37c1-4f9e-ba68-291284f4961f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92698411-c383-4020-83d4-e984d3078517",
   "metadata": {},
   "source": [
    "#### 5.5.2 Applying Counterfactual to the ANN Model\n",
    "* E3D. Thesis - Test different XAI methods with the ANN Model (Counterfactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fad931-cfb1-4ba4-8800-5c4863a5f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902ce86-641a-4980-b3c8-8293193ac671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show floats with 2 decimal places and avoid scientific notation\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26253c77-399c-4ec0-a38e-4cb2514cc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume: X_train, X_test, model\n",
    "query_instance = X_test_scaled.iloc[0].copy()\n",
    "query_instance_values = query_instance.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b1d22-9da5-4393-9022-c672bd70ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, x):\n",
    "    \"\"\"\n",
    "    Predict class for a single instance.\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(x.reshape(1, -1))[0,1]  # probability of class 1\n",
    "    else:\n",
    "        return model.predict(x.reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9c3da-f3ea-49a7-874c-1fadb934987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2):\n",
    "    \"\"\"Euclidean distance between two instances\"\"\"\n",
    "    return np.linalg.norm(x1 - x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ff7fb-0e6a-43db-9d90-42320c7df0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfactual(model, x0, total_cfs=3, max_trials=10000, step_size=0.1):\n",
    "    \"\"\"\n",
    "    Generates counterfactuals using random perturbations.\n",
    "    \"\"\"\n",
    "    cf_list = []\n",
    "    trials = 0\n",
    "    \n",
    "    while len(cf_list) < total_cfs and trials < max_trials:\n",
    "        # Perturb features randomly\n",
    "        x_cf = x0 + np.random.normal(0, step_size, size=x0.shape)\n",
    "        \n",
    "        # Check if prediction flips\n",
    "        pred_orig = predict_label(model, x0)\n",
    "        pred_cf = predict_label(model, x_cf)\n",
    "        \n",
    "        # For binary classification, flip the label\n",
    "        if (pred_orig < 0.5 and pred_cf >= 0.5) or (pred_orig >= 0.5 and pred_cf < 0.5):\n",
    "            cf_list.append(x_cf)\n",
    "        \n",
    "        trials += 1\n",
    "    \n",
    "    return np.array(cf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28644c6-46ab-490b-8680-c469dba1195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf459a7-4284-4f08-b2a3-da49a18cf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals = generate_counterfactual(model=model, x0=query_instance_values, total_cfs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fff76a-530d-4baa-8746-96b8e4760d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "explanation_time = end_time - start_time\n",
    "print(f\"Counterfactual on ANN (Explanation Time): {explanation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a5e2e-b160-40e8-9b45-1190dfc02240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = pd.DataFrame(counterfactuals, columns=X_test_scaled.columns)\n",
    "df_compare = pd.concat([query_instance.to_frame().T, df_cf], keys=['Original', 'Counterfactual'])\n",
    "df_transposed = df_compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651168c7-4fa9-4325-afa6-1de5edf40a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d9da6-430e-46cc-a713-2e9264658dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77c6f4-f330-4e55-896d-ee376a44849e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b90c489-041f-4b33-9a99-ebb9871a28cd",
   "metadata": {},
   "source": [
    "#### 5.5.3 Applying Adversarial Explanations to the ANN Model\n",
    "* E3D. Thesis - Test different XAI methods with the ANN Model (Adversarial Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52614b05-e111-4d51-b709-c9013bd02f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67243e-845e-4e66-a91e-97220569a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define adversarial explanation function \n",
    "def adversarial_explanation(model,\n",
    "    x_orig,                     # 1D numpy array (already preprocessed to model input space)\n",
    "    target_label=None,          # desired target label (0 or 1). If None -> flip original label.\n",
    "    feature_bounds=None,        # list of (min, max) for each feature (in same scaled space as x_orig)\n",
    "    maxiter=200,                # DE iterations\n",
    "    popsize=15,                 # DE population size multiplier\n",
    "    penalty_coef=50.0,          # strength of constraint penalty\n",
    "    norm='l2',                  # 'l2' or 'linf'\n",
    "    random_state=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Find a minimal perturbation delta such that model.predict_proba(x_orig + delta) yields target_label.\n",
    "    Uses differential_evolution (global, gradient-free).\n",
    "    Returns: dict { 'delta', 'x_adv', 'orig_prob', 'adv_prob', 'success', 'distance' }\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    x_orig = np.asarray(x_orig).astype(float).ravel()\n",
    "    n = x_orig.size\n",
    "\n",
    "    # current predicted label and probability\n",
    "    prob_orig = model.predict_proba(x_orig.reshape(1, -1))[0,1]\n",
    "    label_orig = int(prob_orig >= 0.5)\n",
    "    if target_label is None:\n",
    "        target = 1 - label_orig\n",
    "    else:\n",
    "        target = int(target_label)\n",
    "\n",
    "    # bounds for delta: by default allow changes within (min_feature - val, max_feature - val)\n",
    "    if feature_bounds is None:\n",
    "        # set bounds from training feature ranges (we'll use training min/max scaled)\n",
    "        # Compute safe bounds around x_orig: +/- 3 STD (in scaled space that's reasonable)\n",
    "        # but to be general, allow range [-clip, +clip] where clip = max(abs(min,max)) * 1.1\n",
    "        # Here we set per-feature bounds to ensure we stay inside plausible values.\n",
    "        fb = []\n",
    "        X_all = np.vstack([X_train_scaled.values, X_test_scaled.values])\n",
    "        min_col = X_all[:, :].min(axis=0)\n",
    "        max_col = X_all[:, :].max(axis=0)\n",
    "        for i in range(n):\n",
    "            # bounds for delta so that x_adv remains in [min_col[i], max_col[i]]\n",
    "            lo = min_col[i] - x_orig[i]\n",
    "            hi = max_col[i] - x_orig[i]\n",
    "            fb.append((lo, hi))\n",
    "    else:\n",
    "        # feature_bounds given as list of (min,max) for each feature in input space\n",
    "        fb = []\n",
    "        for i, (mn, mx) in enumerate(feature_bounds):\n",
    "            fb.append((mn - x_orig[i], mx - x_orig[i]))\n",
    "\n",
    "    # objective: minimize norm(delta) + penalty * max(0, threshold - prob_target)\n",
    "    def objective(delta_flat):\n",
    "        delta = np.array(delta_flat)\n",
    "        x_candidate = x_orig + delta\n",
    "        # clip to bounds (avoid invalid values)\n",
    "        # compute predicted probability of target class\n",
    "        proba = model.predict_proba(x_candidate.reshape(1, -1))[0, 1]\n",
    "        # fitness for target: we want proba_target >= 0.5 if target==1; else <=0.5\n",
    "        if target == 1:\n",
    "            violation = max(0.0, 0.5 - proba)\n",
    "        else:\n",
    "            violation = max(0.0, proba - 0.5)\n",
    "        # distance measure\n",
    "        if norm == 'l2':\n",
    "            dist = np.linalg.norm(delta)\n",
    "        elif norm == 'linf':\n",
    "            dist = np.max(np.abs(delta))\n",
    "        else:\n",
    "            dist = np.linalg.norm(delta)\n",
    "        # objective: distance + penalty * violation\n",
    "        return dist + penalty_coef * violation\n",
    "\n",
    "    # differential evolution\n",
    "    result = differential_evolution(\n",
    "        objective,\n",
    "        fb,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popsize,\n",
    "        tol=1e-5,\n",
    "        polish=True,\n",
    "        updating='deferred',\n",
    "        seed=random_state,\n",
    "        mutation=(0.5, 1.0),\n",
    "        recombination=0.7,\n",
    "    )\n",
    "\n",
    "    delta_opt = result.x\n",
    "    x_adv = x_orig + delta_opt\n",
    "    prob_adv = model.predict_proba(x_adv.reshape(1, -1))[0,1]\n",
    "    success = (prob_adv >= 0.5 and target == 1) or (prob_adv < 0.5 and target == 0)\n",
    "    distance = np.linalg.norm(delta_opt) if norm == 'l2' else np.max(np.abs(delta_opt))\n",
    "\n",
    "    return {\n",
    "        'delta': delta_opt,\n",
    "        'x_adv': x_adv,\n",
    "        'orig_prob': prob_orig,\n",
    "        'adv_prob': prob_adv,\n",
    "        'success': success,\n",
    "        'distance': distance,\n",
    "        'result_obj': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7265775-e4d0-4cc1-a2e8-98bec78e1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded12e2-b7e0-463f-9ee2-5acddb98d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run adversarial explanation for one test instance\n",
    "idx = 0\n",
    "x0 = X_test_scaled.iloc[idx].values  # already scaled to model input\n",
    "ae = adversarial_explanation(model, x0, target_label=None, maxiter=100, popsize=10, penalty_coef=200.0, norm='l2', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73baa5-1825-4fae-9598-e906ff475f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "explanation_time = end_time - start_time\n",
    "print(f\"Adversarial Expanations on ANN (Explanation Time): {explanation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f522e8-2aca-40f2-9ea1-240e8e17ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original prob (class=1):\", ae['orig_prob'])\n",
    "print(\"Adversarial prob (class=1):\", ae['adv_prob'])\n",
    "print(\"Success flipped?:\", ae['success'])\n",
    "print(\"L2 distance of delta:\", ae['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0f839-ec1f-47e4-b9b4-da066387b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top changed features\n",
    "delta = ae['delta']\n",
    "df_changes = pd.DataFrame({\n",
    "    'feature': X_test_scaled.columns,\n",
    "    'orig': x0,\n",
    "    'adv': ae['x_adv'],\n",
    "    'delta': delta,\n",
    "    'abs_delta': np.abs(delta)\n",
    "}).sort_values('abs_delta', ascending=False)\n",
    "\n",
    "print(\"\\nTop feature changes (by absolute perturbation):\")\n",
    "print(df_changes.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233cecd-1fcd-4b7e-9e7c-1aecb1c959fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 10 features by absolute change\n",
    "top_changes = df_changes.head(10).sort_values('abs_delta', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(top_changes['feature'], top_changes['delta'], color='skyblue')\n",
    "plt.xlabel('Change (delta)')\n",
    "plt.title('Top 10 Features Changed by Adversarial Example')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00c023-c01e-4718-82dc-7686157ad82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38c796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
